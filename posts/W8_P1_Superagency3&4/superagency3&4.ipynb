{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d29df62-c99e-4430-9006-35d42f5af239",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Is AI Bringing More Resources but Less Opportunities?\"\n",
    "description: \"Discussion on AI and the job market\" \n",
    "author: \"Haowei\"\n",
    "date: \"10/15/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Society\n",
    "  - AI Ethics\n",
    "  - Book Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dab6f-19f0-4b65-980c-bd5975ef767d",
   "metadata": {},
   "source": [
    "# Is AI Bringing More Resources but Less Opportunities?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66142dda-bc86-4623-83cc-7dd417fd3e16",
   "metadata": {},
   "source": [
    "## Positive and Negative Views on AI. \n",
    "In Chapter 3 of Superagency, Hoffman and Beato discussed the great potential of LLM being used in creating mental health support. Using that as a case, the authors get to one of their central arguments in this book: Bringing a positive mindset of “what could possibly go right” about AI. The authors argue that AI has so much potential that bringing a problemism view will hinder progress on AI improvement and application, and testing is inevitable and necessary for AI to reach our expectations. \n",
    "\n",
    "However, I wonder how much exposure is reasonable to conduct testing for a not fully polished AI tool on actual human users. Hoffman and Beato referred a lot to Koko, the mental health App that leveraged the gpt model to allow users draft messages to each other. Although Koko supported countless young people struggling with lack of mental health resources, I wonder if it worthes to take the risks of AI formulating negative messages. Koko was based on more traditional machine learning and natural language processing and used less of generative AI capacity, yet many AI Apps are building to serve areas with high stakes such as mental health, medical situation, youth education…How can testing be done to gather data that can improve the tool but not in the cost of harming some initial users?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda352d9-677d-41a2-b565-809ebe11fd27",
   "metadata": {},
   "source": [
    "## More resources, less opportunities?\n",
    "While the authors are envisioning the enormous resources AI will bring for supporting mental health workers shortage, I can’t help to think of the recent competitive job market and unemployment rate. There are financial reasons in the challenging job market right now, yet from Wharton’s report, companies are hiring less junior level employees because of more AI usage. Unemployment and increasing competition in pre and post higher education are causing more anxiety in young to middle age people, which can directly lead to more anxiety. While AI powered tools can support people with mental health concerns, it is at the same time, generating problems. A part of the shortage in healthcare workers and teachers are due to low pay and high job requirements rather than lack of resources in nature. Using AI to fill up this shortage cannot change the root cause of labor shortage. \n",
    "\n",
    "In Chapter 4, the authors mentioned that some argued that AI is only making a small group of people wealthy, but they soon reverted that by analyzing that AI brings free access to information to the general public without competition. Everyone can enjoy the information without at the cost of someone else' s benefits or rights. I totally agree and think that this is true, but the fact that so many people are using AI is changing how the society and job landscape work, and people need to accommodate that change. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0e642b8-6e5e-4940-97c7-805cca2d7a79",
   "metadata": {},
   "source": [
    "![AI and Employment](AI_and_Employment.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6d9ab1d-bd54-4519-812a-5cc821c053c8",
   "metadata": {},
   "source": [
    "## Where should AI be used?\n",
    "From my personal experience and observations, I think AI should not be used to overly replace human to human interactions. Sharing feelings and conversations with AI still feels nothing like talking with a live human, even if they’re a stranger on the other side of the phone. Users of Koko stop liking the messages once they figure out the message is co-created by AI. AI can serve as an alternative to human interactions, but hardly as a replacement. Therefore, the question is: How much human-human interaction versus human-ai interaction do we need? \n",
    "\n",
    "One direction I can think of is to use AI to test and create safer AI tools. Answering the question at the beginning of this blog on “How can testing be done to gather data that can improve the tool but not at the cost of harming some initial users?”, more AI should be used to do repetitive work and provide analytics that are beyond human brain or capacity. It may also be used as a tool to augment human to human interaction, for example the multimodal nature of AI mentioned in Chapter 4 may bring people more ways to experience and process information. It should not be used to replace direct conversations or interactions between humans. \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f5b92535-7b05-43b7-9dbe-585d2c9c73b0",
   "metadata": {},
   "source": [
    "## To Conclude:\n",
    "After reading Chapter 3 and 4, I understand that the authors’ advocated opinion on more positive attitudes on AI, but I wonder where the boundary should be. It probably requires decades of exploration and efforts of the whole society. I am curious about how policy makers would think of this, which I will share some thoughts in another post. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87be0e62-e718-4505-89a6-ea0bcb410638",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
