{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d29df62-c99e-4430-9006-35d42f5af239",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Asking LLM for Guitar Chords\"\n",
    "description: \"Reflection\" \n",
    "author: \"Haowei\"\n",
    "date: \"11/18/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Creativity\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dab6f-19f0-4b65-980c-bd5975ef767d",
   "metadata": {},
   "source": [
    "# Asking LLM for Guitar Chords \n",
    "I wanted to try using AI to generate guitar chords because it sits at an interesting intersection of creativity, learning, and convenience. When I play guitar, I am usually not aiming for a perfect or authoritative transcription. I just want something playable that lets me start engaging with the song quickly. Traditional chord websites often require digging through multiple versions, dealing with ads, or accepting someone else’s interpretation without much context. AI, in contrast, offers a conversational way to access this information. I can ask for chords the same way I would ask a friend who plays guitar, and I can immediately follow up if something feels off.\n",
    "\n",
    "However, this exploration made it clear that AI-generated chords are best understood as starting points rather than answers. The first response I received sounded musically plausible, but it did not align with the song I had in mind. The opening lyric was wrong, which signaled that the model was relying on common songwriting patterns instead of the actual structure of the song. This highlighted a broader pattern I’ve noticed in working with LLMs: they are very good at producing outputs that feel right, even when they are not grounded in specific details.\n",
    "\n",
    "As a result, my process became more iterative and reflective. I tested the chords by playing them, compared them against my memory of the song, and then corrected the model by pointing out the exact opening line. That single piece of concrete feedback shifted the output closer to what I needed. Rather than treating the AI as an authority, I treated it as a collaborator that responds to clarification and correction.\n",
    "\n",
    "This process closely mirrors how learning by ear works in music. You try something, notice where it diverges from what you hear, and adjust. In that sense, AI did not replace my musical judgment. Instead, it accelerated the trial-and-error loop. This small experiment reinforced my broader takeaway from this exploration: AI is most effective when users stay actively engaged, listening carefully, checking assumptions, and using the tool to support thinking and practice rather than to bypass them.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f898228-cf0d-4c26-bc57-6570565234e0",
   "metadata": {},
   "source": [
    "![Guitar Chords](chords.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a8f24db-3068-4601-ad89-aa188c6af39e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
