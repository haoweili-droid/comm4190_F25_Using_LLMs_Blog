{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d29df62-c99e-4430-9006-35d42f5af239",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Building trust with AI\"\n",
    "description: \"What do you consider when picking an AI tool? or do you consider anything at all?\" \n",
    "author: \"Haowei\"\n",
    "date: \"9/27/2025\"\n",
    "categories:\n",
    "  - AI Ethics\n",
    "  - Agency\n",
    "  - Book Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358b2fd-c2cc-4026-9a0f-0656a402481c",
   "metadata": {},
   "source": [
    "# How to facilitate the process of building trust with AI to improve tool using and making?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fc1c44-91c5-41be-b695-0488d7712088",
   "metadata": {},
   "source": [
    "<div align=\"center\">\n",
    "  <img src=\"superagency.jpg\" alt=\"superagency by Reid Hoffman and Greg Beato\" width=\"400\">\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dab6f-19f0-4b65-980c-bd5975ef767d",
   "metadata": {},
   "source": [
    "In the intro and Chapter 1 of Superagency by Geoff Hoffman and Greg Beato, the main question centers around how humans pertain their agency with the power of AI. It’s always been a controversy of whether AI will be able to do so much that it hinders human’s ability to live and think independently. The authors traced back to the 6 months of LLM advancement shut down in 2023 and showed that in 2022, only 35% of Americans participated in a survey that believed that AI based products and services have more benefits than harm to human society. Regarding this worrisome, the authors proposed that AI is just part of the toolkit that humans invent. Learning how to better leverage it will bring more benefits to us than to thinking of how to restrict it. Three years after the mass AI panic and hype, people are now more used to working with AI tools in different parts of our lives, from writing papers to getting laptops fixed to getting food order, people start to work efficiently with AI and realize its massive potential can be used within control.\n",
    "\n",
    "With most people acknowledging the benefits of LLMs and AI tools, the questions now become: how can we know which AI to trust and use for a specific task? Hoffman and Beato mentioned two major ideas that I found interesting. One of them was iterative development, which was initiated by OpenAI for inviting the public to participate in the development of LLM products. This allows the developers to better understand users’ opinions and create more user centered tools but also transfer the control and agency back to the users. The other argument they had about building trusts in AI involved trusts beyond the technologies themselves but also in the developers, regulators, and other users of the technologies. This trust between multiple stakeholders is essential for the general public because people need to know about how models are trained and created and what perspectives or potential biases may exist under those training. This is something that is generally lacking in the current stage of human Ai interaction in society. Just as how we read the product description of electronics, furniture and even food they buy everyday, AI tools should also be given enough review and consideration before someone starts to use them routinely. I believe this will help with opening an outlet for people to start building trust with stakeholders of AI tools and use AI to achieve their goals that follow their original purpose. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0fa6f-f611-4389-888f-658fa04cbdc9",
   "metadata": {},
   "source": [
    "**Potential actions to build trust with AI and its stakeholders:**\n",
    "\n",
    "- A website as a guide matching people with the best AI tool to achieve their goals.  \n",
    "  - The website should include detailed information about the LLM of the tool, including model name, features, and a description of the dataset used to train the model.  \n",
    "  - *Potential problem:* These websites may also contain biased “narratives” or miss certain tools.  \n",
    "\n",
    "- A community where everyone can share information and resources on AI tools.  \n",
    "  - Tags and labels can be used to help people find relevant AI tools when they need them.  \n",
    "  - *Potential problem:* The content in the community may be hard to manage, and information needs to be verified (perhaps LLMs can help with this too…).  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5da7d173-79a0-46c9-a853-dc632e5c71a6",
   "metadata": {},
   "source": [
    "Superagency is an obvious pro-AI book, yet it shared many reasons why AI should be embraced by people rather than constrained for us to earn more agency. I hope to further build my idea in helping humans build understanding on AI tools as I keep reading the book."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7bc328b-5daa-4515-9ca3-3f996aeae2d1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
