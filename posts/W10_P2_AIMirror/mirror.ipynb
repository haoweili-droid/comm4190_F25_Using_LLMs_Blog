{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d29df62-c99e-4430-9006-35d42f5af239",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"AI as a Mirror\"\n",
    "description: \"another way to think of AI\" \n",
    "author: \"Haowei\"\n",
    "date: \"11/1/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Creativity\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dab6f-19f0-4b65-980c-bd5975ef767d",
   "metadata": {},
   "source": [
    "## AI as a Mirror\n",
    "\n",
    "When people talk about large language models, they often describe them as tools, assistants, or even collaborators. Recently, I started thinking about them in a different way: as mirrors. By this, I do not mean that AI has self-awareness or intentions of its own, but that its responses often reflect the way I think, ask questions, and frame problems. The language, structure, and assumptions in my prompts seem to shape not just what the model answers, but how it answers.\n",
    "\n",
    "This idea raises an interesting question: if an LLM is trained to predict the most likely continuation of text, then how much of what I see in its output is actually coming from me? If AI mirrors my thinking style, then interacting with it might tell me as much about my own cognition as it does about the model’s capabilities.\n",
    "\n",
    "To explore this idea, I decided to treat my interactions with an LLM as a small experiment rather than casual use."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66142dda-bc86-4623-83cc-7dd417fd3e16",
   "metadata": {},
   "source": [
    "To test whether AI reflects my thinking style, I intentionally varied my prompts while keeping the topic constant. In some cases, I used highly structured prompts with explicit steps, constraints, and goals. In others, I wrote vague or open-ended prompts that resembled how I might think out loud when I am unsure.\n",
    "For example, when I asked the model to help me reflect on a learning theory, I tried two versions. One prompt explicitly asked for definitions, comparisons, and examples. Another prompt simply said something like, “I’m confused about this theory. Can you help me think through it?” I also experimented with tone, sometimes writing in a confident, academic style, and other times using tentative language that emphasized uncertainty.\n",
    "In addition, I paid attention to moments when I pushed back on the model’s responses. When I disagreed or asked for clarification, I noticed how the model adjusted its reasoning to align more closely with my perspective."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dda352d9-677d-41a2-b565-809ebe11fd27",
   "metadata": {},
   "source": [
    "The differences in the AI’s responses were noticeable. When my prompts were structured and precise, the model responded in a similarly organized way, often producing outlines, bullet points, or step-by-step explanations. When my prompts were exploratory or uncertain, the responses became more conversational and reflective, sometimes mirroring my hesitations or questions rather than resolving them immediately.\n",
    "Even more interesting was how my assumptions showed up in the output. If I framed a question as if one explanation was already correct, the model tended to reinforce that framing rather than challenge it. On the other hand, when I explicitly invited critique or alternative perspectives, the model became more balanced and analytical.\n",
    "In some cases, I realized that what I initially interpreted as the model’s “bias” was actually my own. The AI was not introducing new assumptions so much as amplifying the ones I had already embedded in the prompt. This made it harder to tell where my thinking ended and the model’s contribution began.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830f2cb8-4ca2-4728-84ea-32648bde328d",
   "metadata": {},
   "source": [
    "![AI as a mirror](mirror.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "87be0e62-e718-4505-89a6-ea0bcb410638",
   "metadata": {},
   "source": [
    "This exploration changed how I think about working with LLMs. Instead of seeing the model as an external authority, I began to see it as a reflective surface. The quality of its responses depended heavily on the clarity, structure, and openness of my own thinking. When my prompts were shallow, the responses felt shallow. When my prompts were thoughtful and reflective, the AI seemed more insightful.\n",
    "\n",
    "This also made me more aware of my responsibility as a user. If AI mirrors my thinking, then careless prompting can reinforce misconceptions, while careful prompting can support deeper understanding. In this sense, interacting with an LLM becomes a metacognitive activity. I am not just asking questions, but also examining how I ask them and what that reveals about my learning habits.\n",
    "\n",
    "Finally, this experience highlighted a limitation that is easy to overlook. Because AI is so good at reflecting back coherent language, it can create the illusion of understanding even when neither the model nor I fully understand the concept. Recognizing this has made me more cautious. I now see value in slowing down, questioning the responses, and treating AI outputs as starting points for reflection rather than final answers.\n",
    "Overall, thinking of AI as a mirror has helped me use it more intentionally. It is not just a tool that gives me information, but a space where my own thinking becomes visible. And in that sense, working with LLMs has become less about outsourcing cognition and more about learning how to see my own thought process more clearly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23704e5d-7212-4175-8a63-ce29c683266f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
