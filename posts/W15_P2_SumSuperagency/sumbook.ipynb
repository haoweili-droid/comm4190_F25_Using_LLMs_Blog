{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d29df62-c99e-4430-9006-35d42f5af239",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Between Optimism and Unease: Rethinking AI Through Superagency\"\n",
    "description: \"A semester-long reflection\" \n",
    "author: \"Haowei\"\n",
    "date: \"12/17/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "  - Book Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dab6f-19f0-4b65-980c-bd5975ef767d",
   "metadata": {},
   "source": [
    "# Between Optimism and Unease: Rethinking AI Through Superagency\n",
    "Reading Superagency throughout this semester felt like having an ongoing conversation with the book rather than reaching a single conclusion at the end. Early on, I was genuinely convinced by the authors’ optimism. They frame AI as something that can increase human agency instead of replacing it, and they support this claim with many real examples. For instance, they describe AI tools used in mental health platforms and community-based applications, arguing that AI can scale care and support in ways humans alone cannot. At that point in the reading, I found myself agreeing with their argument that focusing only on AI’s risks can prevent us from seeing its potential benefits.\n",
    "\n",
    "As I kept reading, though, my reaction became more mixed. A lot of the examples they use come from industry settings, such as professional platforms and data-driven tools connected to companies like LinkedIn. While these cases are persuasive, they also made me question who AI is really designed for. The authors often suggest that AI will broadly benefit society, but I struggled with this assumption. Not everyone has equal access to AI tools, and not everyone is equally represented in the data these systems are trained on. When the book discusses data as a resource for improving AI, it sometimes feels like it assumes that more data automatically leads to better outcomes, without fully addressing whose data is being used and who actually benefits.\n",
    "\n",
    "One section that shifted my thinking was the discussion of how AI systems are tested and evaluated. Before reading Superagency, I tended to think of AI development as fast-moving and poorly controlled. The authors describe benchmarks, internal testing standards, and technical evaluations that developers use to measure performance and reduce errors. Learning about these practices made AI feel less chaotic and more like a system that is constantly being adjusted. While this did not erase my concerns about bias or misuse, it helped me see that AI development involves more intentional decision-making than I previously assumed.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f898228-cf0d-4c26-bc57-6570565234e0",
   "metadata": {},
   "source": [
    "![Superagency (an AI generated cover page](cover.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a8f24db-3068-4601-ad89-aa188c6af39e",
   "metadata": {},
   "source": [
    "The most memorable example in the book for me was the comparison between AI and the early days of automobiles. The authors argue that when cars were first introduced, they caused many accidents and deaths, yet society still chose to adopt them because of the long-term benefits they provided. This analogy made me uncomfortable, but it also stuck with me. It forced me to think about whether it is realistic to expect new technologies to be completely safe from the start. At the same time, it raised ethical questions the book does not fully answer, such as who is expected to bear the risks during early adoption and who gets to decide that those risks are acceptable.\n",
    "\n",
    "By the end of the semester, I did not walk away from Superagency with a clear stance on whether AI should be more regulated or more freely developed. Instead, the book pushed me to think more critically about boundaries. For example, AI used for education or productivity might require very different standards than AI used in areas like mental health or decision-making about people’s lives. Treating all AI applications the same does not seem realistic, and I wish the book had spent more time addressing how context should shape regulation and testing.\n",
    "\n",
    "Overall, Superagency did not fully convince me to adopt the authors’ optimism, but it did change how I think about AI. It helped me move away from seeing AI as either entirely dangerous or entirely beneficial. Instead, I now see it as something shaped by human choices, incentives, and power structures. As I think about AI beyond this class, I want to keep engaging with questions the book raises but does not resolve, especially around access, accountability, and who gets to define what counts as a “good” use of AI.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c047525d-7a3b-45a8-b139-4b2a7e1ef270",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
