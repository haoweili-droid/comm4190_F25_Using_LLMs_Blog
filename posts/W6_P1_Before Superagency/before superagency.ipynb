{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d29df62-c99e-4430-9006-35d42f5af239",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"The Long Way to Go Before Superagency\"\n",
    "description: \"Big knowledge is conditional.\" \n",
    "author: \"Haowei\"\n",
    "date: \"10/4/2025\"\n",
    "categories:\n",
    "  - AI Ethics\n",
    "  - Agency\n",
    "  - Book Review\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2358b2fd-c2cc-4026-9a0f-0656a402481c",
   "metadata": {},
   "source": [
    "# The Long Way to Go Before Superagency "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1eb1a6b-d3d1-4dbc-9955-0dd42837ed19",
   "metadata": {},
   "source": [
    "<div align=\"center\"> <img src=\"socialmediaicon.jpg\" alt=\"an image with different mainstream social media icons\" width=\"200\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a79362d-1ab5-4be9-aae4-8cd449cfbd8f",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left;\"><em>Social Media Around Us</em></p>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dab6f-19f0-4b65-980c-bd5975ef767d",
   "metadata": {},
   "source": [
    "After reading Chapter Two of the book *Superagency*, I see clear tradeoffs between privacy and scalability and conditions that are required for us to enjoy the freedom of AI, but I also realized how AI literacy and equal access is an essential presumption for us to fully leverage on the benefits AI brings. \n",
    "\n",
    "This chapter started with an analogy of today’s age to the surveillance world in the book *1984* by George Orwell, picturing people’s fear that AI may invade privacy and agency, and in the worst cases of our worries, AI may take over our thoughts and replace us. In the second half of this chapter, Hoffman (one of the authors of Superagency) started to discuss that emerging technologies and AI is bringing us more connected resources and information that allows people to build up networks and make better choices. For example, by looking up people on LinkedIn you will know someone’s skillset and if they are an ideal person you want to work with. Hoffman implied that in today’s era, creating public identities is opening up so many opportunities for human agencies that outweighs the risks to privacy and will not hinder our free will. All these advantages were brought by distributing intelligence through big data, with the formation of *Big Knowledge*, which is the name of this chapter. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18f0fa6f-f611-4389-888f-658fa04cbdc9",
   "metadata": {},
   "source": [
    "What he argued was totally true, that LinkedIn or other social media is enabling people to know more about others and this world and that humans can use AI and algorithm power to gather and manage big data to make more comprehensive decisions. However, I think all of these benefits will need three important conditions: people’s **awareness**, **consent**, and **free choices** on data and technology usage. \n",
    "\n",
    "These three things come in series. Only if you know that AI is gathering your data can you decide whether to opt in or not. Only if you can choose to not share your information can you be called to have free will in this data era. Unfortunately, these conditions have not all been met in our daily lives, yet AI is operating wildly. Everytime you select “I agree” to an internet consent, do you really read and understand what it says by “We use cookies to improve your browsing experience and analyze site traffic”. With the one time that you decided to choose “I do not agree”, you found out that you can’t even keep browsing this website. \n",
    "\n",
    "Products that leverage LLMs now are not fully empowering free will and human agency with these forceful data collection through internet services and consent questions. Hoffman can easily name out the benefits of AI because he has the knowledge and resources to determine which algorithm is good for use and how to use LinkedIn to create a perfect profile rather than unintentionally disclose one’s privacy. \n",
    "\n",
    "I tried using AI meeting assistance tools in the beginning of 2024 when AI audio transcription started to thrive, and the agent went to a lab meeting after I graduated and sent everyone a meeting note. I hope no one notices it and thought I was trying to eavesdrop on conversations, but this happened simply because I didn’t turn off the access of the tool to my Google calendar through a bunch of consents during my onboarding. I have also seen friends sending posts on LinkedIn about every event they attended, but they didn’t even know that those posts were sent. \n",
    "\n",
    "Even if we as college and graduate students make these mistakes and expose ourselves to risks in privacy, then what about average people who have only heard about the acronym AI but never tried the tool themselves? What about teenagers and people who never go to college and took a lesson on prompt engineering and cybersecurity? What about elderly people who some even cannot read the tiny consent message? "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b05c3bb6-3e7d-4604-b887-52684706a793",
   "metadata": {},
   "source": [
    "<div align=\"center\"> <img src=\"privacynote.png\" alt=\"privacy notes on internet\" width=\"400\"> </div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8099fa45-0e95-4447-8693-e7d051ff48bb",
   "metadata": {},
   "source": [
    "<p style=\"text-align: left;\"><em>We Value Your Privacy Note<em></p>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7c5aa6b4-3e7c-45ed-98fb-51f1ed9f227a",
   "metadata": {},
   "source": [
    "To explore AI’s ability in debating and role taking, we had this activity to debate with an AI chat agent on different positionalities towards LLMs that the Book Superagency listed: **Doomers**, who believe AI poses an existential threat and should be stopped; **Gloomers**, who are skeptical of AI’s benefits and advocate for strict regulation to manage its harms. **Zoomers**, who enthusiastically push to accelerate AI development with minimal oversight; and **Bloomers**, who are cautiously optimistic, supporting AI’s promise while calling for measured risk management and public involvement. \n",
    "\n",
    "I was a firm Bloomer at that time and I asked gpt-4 to be a Gloomer to debate with me. It kept pointing out the lack of regulations in AI while products are created to be used by the public. Now after reading this chapter of Superagency, I felt my position was further swayed by Gloomers as we need more literacy and education on responsible AI and data usage before it further enters into our lives. I hope we as general consumers of LLM products are not just one data point in the big data, but active users, coordinators and even developers of big knowledge. \n",
    "\n",
    "We will reach superagency, but there is still a long way to go. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9747386-2754-4442-b02c-06168109f420",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
