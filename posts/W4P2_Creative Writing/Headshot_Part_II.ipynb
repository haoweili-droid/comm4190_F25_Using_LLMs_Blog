{
 "cells": [
  {
   "cell_type": "raw",
   "id": "ac87cceb-7a1a-4d9e-a58d-60edec710642",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Artisticalize your headshot? A prompting journal and comparison between GPT-5 and gemini 2.5 flash (PartII)\"\n",
    "description: \"Can AI become my visual designer?\" \n",
    "author: \"Haowei\"\n",
    "date: \"9/18/2025\"\n",
    "categories:\n",
    "  - Prompt Engineering\n",
    "  - Multimodel\n",
    "  - Image Generation\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfc437b2-20d6-4c55-a724-68169fa415b1",
   "metadata": {},
   "source": [
    "# Artisticalize your headshot? (Part II)\n",
    "A prompting journal and comparison between GPT-5 and gemini 2.5 flash"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a48bde16-383f-4ffb-ab18-705fae312691",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "**Personally, I would choose GPT-5.**\n",
    "\n",
    "While Gemini 2.5 flash is like a student who is always on time for class, early for homeworks but does not hand over the most impressive projects, GPT-5 is like the naughtiest student in the class who never follows the traditional route but surprises you with its creativity. The higher accuracy for GPT-5 to understand my request and reach a good quality product at the beginning won my vote on it. I think I value the quality of work more than following a specific format I asked for (I will be such an annoying boss if this is a real work scenario…). \n",
    " \n",
    "Finding out GPT-5 did better was a little surprising to me. Before I started this project, Gemini 2.5 had more of my bet because it had the obvious “create image” tab that I started with, and I knew that Gemini is known for its indepth logic and research skills, which made me think maybe it will create better images. \n",
    "\n",
    "**For Better Comparison Tests:**\n",
    "There are some limitations that showed up in this small experiment and can be improved in the future. \n",
    "More conditions should be in control to better compare model ability in creating images or other specific fields. For example, both models should be in “create image” mode. \n",
    "I should also try to control the follow up conversation prompts as much as possible, but this requires more discussions and experiments on whether controlling every single prompt will be an accurate assessment on model ability. (this will be further explored in future blogs on video generation)\n",
    "Prompting can be improved by adding semantic context and splitting information in further chunks. \n",
    "Overall, LLMs are now pretty good at high level (not detailed adjustments) visual design, as models can now quickly interpret users’ preference and make similar but creative visual products. With this headshot redesign task can be done on general chat agents (ChatGPT and Gemini), publics can now access fast iterative creative design service in a few minutes. This makes me think of how designers may use AI tools in their work and the role of designers in the future. With AI tools completing many design drafting, would more graphic and visual designers move on to in depth design fields such as 3d modeling or would there be even more needs in design research for designers to understand customers’ needs and bridge the communication between end user and AI design tools?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f5bdb95-2292-4535-b22a-e4af2ce430b6",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
