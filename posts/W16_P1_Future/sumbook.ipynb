{
 "cells": [
  {
   "cell_type": "raw",
   "id": "6d29df62-c99e-4430-9006-35d42f5af239",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Revisit My Journey of AI\"\n",
    "description: \"From COMM 4190 to further...\" \n",
    "author: \"Haowei\"\n",
    "date: \"12/17/2025\"\n",
    "categories:\n",
    "  - LLMs\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e775887-38ee-448f-9d38-ed406d1d03b2",
   "metadata": {},
   "source": [
    "# Revisit My Journey of AI"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f898228-cf0d-4c26-bc57-6570565234e0",
   "metadata": {},
   "source": [
    "![My AI Journey (an AI generated cover page](revisit.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e4dab6f-19f0-4b65-980c-bd5975ef767d",
   "metadata": {},
   "source": [
    "As the semester comes to an end, rereading my blog posts feels like looking at a timeline of how my interaction with AI has changed. At the beginning, AI felt exciting, almost magical. I was curious about what it could generate, how fast it could respond, and how many tasks it could take off my plate. Over time, though, my focus shifted. Instead of asking “What can AI do?”, I started asking “What actually happens when we rely on it?” and “What kind of future are we building with these tools?”\n",
    "\n",
    "One thing this semester made very clear to me is that AI is not something we will simply “use” occasionally. It is becoming embedded in how we learn, work, design, and communicate. Because of that, the most important question is no longer whether AI is good or bad, but how we choose to interact with it. Across my experiments, the moments that taught me the most were not when AI worked perfectly, but when it failed quietly: when it hallucinated a memory, overexplained a concept, or confidently filled in gaps that did not exist. Those moments forced me to slow down and realize how easy it is to confuse fluency with truth.\n",
    "\n",
    "Looking forward, this feels like a key challenge for the future of AI. As models become more polished and multimodal, their outputs will feel increasingly natural and authoritative. That makes human judgment even more important, not less. My experiences with AI companions, learning tools, and creative workflows showed me that AI works best when it is treated as part of a larger system rather than as a standalone solution. Without clear constraints, context, and accountability, even well-intentioned AI tools can introduce subtle but serious risks, especially in high-stakes areas like education, research, and mental health.\n",
    "\n",
    "At the same time, this course also made me optimistic. When AI is thoughtfully designed and intentionally used, it can genuinely support learning and creativity. I saw this when experimenting with AI-generated study guides, where the model helped surface misconceptions instead of just providing answers, and when testing collaborative or multimodal tools that supported reflection rather than replacing it. These experiences made me believe that the future of AI in learning is not about automation, but about augmentation: helping people think more clearly, reflect more deeply, and engage more meaningfully.\n",
    "\n",
    "One of the biggest shifts for me was realizing how much AI reflects the way I show up to it. Over the semester, I began to see AI less as an independent intelligence and more as a mirror. The structure, tone, and assumptions in my prompts shaped the responses I received. When I was vague, the output was vague. When I was careless, the output was misleading. When I was intentional, critical, and reflective, the AI became genuinely useful. This makes me think that future AI literacy is not just about knowing how models work, but about learning how to ask better questions and recognize when not to accept an answer at face value.\n",
    "\n",
    "As AI continues to evolve, I think the real work ahead is human work. We need clearer norms, better education, and stronger values guiding how AI is integrated into everyday systems. Governance, transparency, and community voices matter not because they slow innovation, but because they shape what that innovation serves. My takeaway from this semester is that AI should not be designed to replace human judgment, care, or interaction. Instead, it should be designed to support them.\n",
    "\n",
    "I am leaving this course with more questions than answers, but that feels appropriate. The future of AI is not something that will simply happen to us. It is something we are actively participating in, through the tools we build, the policies we support, and the ways we choose to use or resist these systems. If this semester taught me anything, it is that being thoughtful, critical, and intentional about AI is not optional. It is a responsibility we will all carry as AI becomes a permanent part of how we live and learn."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2a18c85-c045-4b40-bf36-4923353b7286",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3-12 (COMM4190)",
   "language": "python",
   "name": "python3-12_comm4190"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
